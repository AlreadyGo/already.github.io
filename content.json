{"meta":{"title":"AlreadyGo","subtitle":null,"description":null,"author":"Hui Zhou","url":"https://alreadygo.github.io"},"pages":[{"title":"tags","date":"2017-10-20T16:09:34.000Z","updated":"2019-10-10T11:48:38.227Z","comments":true,"path":"tags/index.html","permalink":"https://alreadygo.github.io/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2017-10-20T17:58:54.000Z","updated":"2019-10-10T11:48:38.203Z","comments":true,"path":"about/index.html","permalink":"https://alreadygo.github.io/about/index.html","excerpt":"","text":"just an ordinary coder …"},{"title":"相册","date":"2017-10-21T02:08:13.000Z","updated":"2019-10-10T11:48:38.203Z","comments":true,"path":"gallery/index.html","permalink":"https://alreadygo.github.io/gallery/index.html","excerpt":"","text":""}],"posts":[{"title":"线程池原理","slug":"阿里巴巴java手册中关于线程的说明","date":"2019-10-10T10:21:48.000Z","updated":"2019-10-11T02:10:13.616Z","comments":true,"path":"2019/10/10/阿里巴巴java手册中关于线程的说明/","link":"","permalink":"https://alreadygo.github.io/2019/10/10/阿里巴巴java手册中关于线程的说明/","excerpt":"","text":"阿里巴巴java手册中关于线程的说明1.【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯正例:1234public class TimerTaskThread extends Thread &#123; public TimerTaskThread() &#123; super.setName(\"TimerTaskThread\");... &#125;&#125; 2.【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。 说明:使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决 资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或 者“过度切换”的问题。3.【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明:Executors 返回的线程池对象的弊端如下: FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 线程池原理参数及工作原理首先是创建线程的 api： 1ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) 这几个核心参数的作用： corePoolSize 为线程池的基本大小。 maximumPoolSize 为线程池最大线程大小。 keepAliveTime 和 unit 则是线程空闲后的存活时间。 workQueue 用于存放任务的阻塞队列。 handler 当队列和最大线程池都满了之后的拒绝策略。 问题：1new ThreadPoolExecutor(10, 20,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()) maximumPoolSize=20会不会起作用？ 提交任务 当前线程数量小于 coreSize 时创建一个新的线程运行,即使有空闲线程。 当前线程数量大于 coreSize并且小于maximumPoolSize，会写入到队列中，只有当队列写满时才会继续创建新的线程 如果coreSize等于maximumPoolSize，那么创建的是一个固定大小的线程池 默认初始化的时候线程池中是没有线程的，只有当有新的任务提交的时候才会创建新线程，但是可以重写prestartCoreThread或者prestartAllCoreThreads方法，使得构造线程池的时候预先启动线程 新线程是通过ThreadFactory创建的 如果线程池里线程数超过corePoolSize，那么空闲时间超过keepAliveTime的线程会被终止掉，默认只会终止maximumPoolSize-coreSize那部分线程，allowCoreThreadTimeOut(true)可以使超时策略对核心线程同样起作用 当线程数超过maximumPoolSize的时候，会采用拒绝策略，jdk提供了几种通用的策略，默认策略，抛出RejectedExecutionException 12345/** * The default rejected execution handler */private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); 每个任务执行前后的钩子函数beforeExecute和afterExecute 具体看代码 关闭线程池 shutdown() 执行后停止接受新任务，会把队列的任务执行完毕。 shutdownNow() 也是停止接受新任务，但会中断所有的任务，将线程池状态变为 stop。 配置线程数1int cupNum = Runtime.getRuntime().availableProcessors(); 一般线程数配置核数的1-2倍 SpringBoot 使用线程池123456789101112131415@Configurationpublic class TreadPoolConfig &#123; /** * 消费队列线程 * @return */ @Bean(value = \"consumerQueueThreadPool\") public ExecutorService buildConsumerQueueThreadPool()&#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(\"consumer-queue-thread-%d\").build(); ExecutorService pool = new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5),namedThreadFactory,new ThreadPoolExecutor.AbortPolicy()); return pool ; &#125;&#125; 使用时： 123456789@Resource(name = \"consumerQueueThreadPool\")private ExecutorService consumerQueueThreadPool;@Overridepublic void execute() &#123; //消费队列 for (int i = 0; i &lt; 5; i++) &#123; consumerQueueThreadPool.execute(new ConsumerQueueThread()); &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://alreadygo.github.io/tags/java/"}]},{"title":"electron实现简单的爬虫客户端","slug":"electron实现简单的爬虫客户端","date":"2018-01-28T05:21:48.000Z","updated":"2019-10-10T11:48:38.202Z","comments":true,"path":"2018/01/28/electron实现简单的爬虫客户端/","link":"","permalink":"https://alreadygo.github.io/2018/01/28/electron实现简单的爬虫客户端/","excerpt":"","text":"下载客户端下载win客户端/绿色免安装 解压客户端压缩包双击crawler-devTools.exe 在控制台执行代码 $toggleCrawlerLog(): 打印log showDevTool(): 调出控制台爬取微博明星分类下前100页数据微博链接在控制台执行以下代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263var config = [&#123; type: &quot;waitFor&quot;, selector: &quot;body .WB_miniblog .PCD_followlist&quot;, timeout: 30&#125;, &#123; type: &apos;script&apos;, async: true, timeout: 60, func: function(args, target, callback) &#123; new Promise(function(f) &#123; if (window.jQuery &amp;&amp; window.$) return f(0); var script = document.createElement(&quot;script&quot;); script.type = &quot;text/javascript&quot;; script.onload = f; script.src = &quot;//cdn.bootcss.com/jquery/2.1.4/jquery.min.js&quot;; document.body.appendChild(script); &#125;).then(() =&gt; &#123; var html = $(&apos;body .WB_miniblog&apos;); function transform(t) &#123; var r = []; t.find(&apos;dd.mod_info&apos;).each((i, v) =&gt; &#123; var o = &#123;&#125;, $t = $(v); o.name = $t.find(&apos;.info_name a strong&apos;).text(); o.url = $t.find(&apos;.info_name a&apos;).attr(&apos;href&apos;); o.connect = $t.find(&apos;.info_connect span:eq(0) .count&apos;).text(); o.fans = $t.find(&apos;.info_connect span:eq(1) .count&apos;).text(); o.weibo = $t.find(&apos;.info_connect span:eq(2) .count&apos;).text(); o.address = $t.find(&apos;.info_add span&apos;).text(); o.intro = $t.find(&apos;.info_intro span&apos;).text(); r.push(o) &#125;); return r; &#125; target.data = transform(html); target.cat = args.cat; callback(); &#125;); &#125;&#125;]let pool = new WebPagePool(5);let callback = data =&gt; &#123; if (!result[data.cat])result[data.cat]=[]; result[data.cat].push(...data.data);&#125;let result=&#123;&#125;;let cats = [&#123;&quot;url&quot;:&quot;https://d.weibo.com/1087030002_2975_1003_0&quot;,&quot;cat&quot;:&quot;明星&quot;,&quot;total&quot;:100&#125;];cats.forEach((cat)=&gt;&#123; let len = cat.total; for(var i=1;i&lt;len+1;i++)&#123; pool.submit(config,Object.assign(&#123;&#125;,cat,&#123;url:`$&#123;cat.url&#125;?page=$&#123;i&#125;`&#125;),callback) &#125;&#125;) 代码说明 均使用jq(sizzle)选择器 config: 对象数组, executor会按顺序执行爬取动作 waitFor: 等待$(‘body .WB_miniblog .PCD_followlist’)元素出现,超时时间30s script: 在页面上执行异步脚本, args(参数,执行任务中传入,其中{url}表示需要请求的链接), target(执行结果,最终会返回), callback(脚本执行完必须调用callback方法) 结果: 本例的结果均放入result变量中 WebPagePool: 页面池, 打开多个页面异步执行爬取任务let pool = new WebPagePool(5); 创建一个有五个页面的页面池 WebPagePool常用方法pool.submit(config,args,callback): config爬取配置,args爬取参数,callback回调方法(callback的参数就是script中的target)pool.queue: 等待执行的任务pool.failQueue: 失败的任务pool.failBack(): 失败任务全部重试pool.isOver(): 页面池的任务是否结束pool.close(): 销毁页面池","categories":[],"tags":[{"name":"js","slug":"js","permalink":"https://alreadygo.github.io/tags/js/"},{"name":"electron","slug":"electron","permalink":"https://alreadygo.github.io/tags/electron/"},{"name":"爬虫","slug":"爬虫","permalink":"https://alreadygo.github.io/tags/爬虫/"}]},{"title":"elasticsearch之cardinality浅析","slug":"elasticsearch之cardinality浅析","date":"2017-11-19T14:18:41.000Z","updated":"2019-10-10T11:48:38.202Z","comments":true,"path":"2017/11/19/elasticsearch之cardinality浅析/","link":"","permalink":"https://alreadygo.github.io/2017/11/19/elasticsearch之cardinality浅析/","excerpt":"","text":"引言大数据时代,类似sum求和或者avg平均值的操作还是相对容易,而比如类似算网站uv或者找出网站访问最频繁访客会比较困难,es中提供了一种cardinality聚合来解决这类问题.123456789101112131415161718curl -XGET &quot;http://localhost:9200/_search&quot; -d&apos;&#123; &quot;aggs&quot;: &#123; &quot;monthly&quot;: &#123; &quot;date_histogram&quot;: &#123; &quot;field&quot;: &quot;timestamp&quot;, &quot;interval&quot;: &quot;month&quot; &#125;, &quot;aggs&quot;: &#123; &quot;visitor_count&quot;: &#123; &quot;cardinality&quot;: &#123; &quot;field&quot;: &quot;ip_address&quot; &#125; &#125; &#125; &#125; &#125;&#125;&apos; 基数估算算法数据集小的时候,当然可以使用hashset,但是数据量过大的时候,内存使用就会很致命.传统的基数计数实现有两种,基于B树和基于bitmap,B树在问题在于不能高效合并,bitmap问题在于bitmap的长度与集合中元素个数无关，而是与基数的上限有关,例如“00100110”表示集合 {2，5，6}。bitmap中1的数量就是这个集合的基数,这两种方法在大数据场景下都会有内存问题.幸运的是,还有其他的基数计数算法.其中比较有名的就是linear counting和loglog counting,HyperLogLog lc算法LC的基本思路是：设有一哈希函数H，其哈希结果空间有m个值（最小值0，最大值m-1），并且哈希结果服从均匀分布。使用一个长度为m的bitmap，每个bit为一个桶，均初始化为0，设一个集合的基数为n，此集合所有元素通过H哈希到bitmap中，如果某一个元素被哈希到第k个比特并且第k个比特为0，则将其置为1。当集合所有元素哈希完成后，设bitmap中还有u个bit为0。则：n^=−mlogumn^=−mlogum为n的一个估计，且为最大似然估计（MLE）。12345678class LinearCounter &#123; BitSet mask = new BitSet(m) // m is a design parameter void add(value) &#123; int position = hash(value) // map the value to the range 0..m mask.set(position) // sets a bit in the mask to 1 &#125;&#125; 精度要求越高，则bitmap的长度越大。随着m和n的增大，m大约为n的十分之一。因此LC所需要的空间只有传统的bitmap直接映射方法的1/10. llc算法LLC的空间复杂度仅有O(log2(log2(Nmax)))，使得通过KB级内存估计数亿级别的基数成为可能.例如,假设基数的上限为1亿，原始bitmap方法需要12.5M内存，而LogLog Counting只需不到1K内存（640字节）就可以在标准误差不超过4%的精度下对基数进行估计,因此目前在处理大数据的基数计算问题时，所采用算法基本为LLC或其几个变种1234567891011121314151617class LogLogCounter &#123; int H // H is a design parameter int m = 2^k // k is a design parameter etype[] estimators = new etype[m] // etype is a design parameter void add(value) &#123; hashedValue = hash(value) bucket = getBits(hashedValue, 0, k) estimators[bucket] = max( estimators[bucket], rank( getBits(hashedValue, k, H) ) ) &#125; getBits(value, int start, int end) rank(value)&#125; 小结 它们都是基于hash而非数值 它们返回的结果都是近似值 linear counting作为一个早期的算法,空间复杂度并不优秀,在基数大的时候结果会很不准,很少单独使用 相比LC其最大的优势就是内存使用极少。不过LLC也有自己的问题，就是当n不是特别大时，其估计误差过大 HyperLogLog是一种结合LC和LLC的一种改进算法,可以用相对固定的内存估算任意大集合的计数 es中主要参考了google出品的HyperLogLog++算法,略有改动,在一定条件下,lc算法会升级到hll算法,详见es源码中org.elasticsearch.search.aggregations.metrics.cardinality.HyperLogLogPlusPlus类. 精度和内存为了节约内存,精度方面会有所牺牲.es提供了一个可配置的precision_threshold参数,来配置cardinality的精度,threshold参数的取值范围在0-4w,默认为3000,精度和内存的使用都与这个参数相关,假设precision_threshold为N,那么你期望每个分片每个聚合桶上的内存大约是8*N字节.源码中可以发现,precision_threshold会转化成precision精度,precision的取值范围在4-18,默认为14,也就是对应precision_threshold=30001234567891011/** * Compute the required precision so that &lt;code&gt;count&lt;/code&gt; distinct entries * would be counted with linear counting. */public static int precisionFromThreshold(long count) &#123; final long hashTableEntries = (long) Math.ceil(count / MAX_LOAD_FACTOR); int precision = PackedInts.bitsRequired(hashTableEntries * Integer.BYTES); precision = Math.max(precision, MIN_PRECISION); precision = Math.min(precision, MAX_PRECISION); return precision;&#125; 下面是一个相对精度丢失图:对于三种阈值,在不同基数下的精度丢失,可以发现就算阈值低至100,在百千万级别的数据量下.精度丢失也在5%以下","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://alreadygo.github.io/tags/elasticsearch/"},{"name":"cardinality","slug":"cardinality","permalink":"https://alreadygo.github.io/tags/cardinality/"}]},{"title":"elasticsearch.yml中重要的配置检查","slug":"elasticsearch-yml中重要的配置检查","date":"2017-11-13T12:33:27.000Z","updated":"2019-10-10T11:48:38.202Z","comments":true,"path":"2017/11/13/elasticsearch-yml中重要的配置检查/","link":"","permalink":"https://alreadygo.github.io/2017/11/13/elasticsearch-yml中重要的配置检查/","excerpt":"","text":"启动集群最小的配置 path.data 和 path.logs数据和日志文件路径123path: logs: /var/log/elasticsearch data: /var/data/elasticsearch 设置多个路径12345path: data: - /mnt/elasticsearch_1 - /mnt/elasticsearch_2 - /mnt/elasticsearch_3 cluster.name集群名1cluster.name: logging-prod node.name节点名1node.name: $&#123;HOSTNAME&#125; bootstrap.memory_lock锁定jvm只用内存,不使用硬盘1bootstrap.memory_lock:true network.host默认为127.0.0.112network.bind_host: 0.0.0.0 #监听所有ip的请求network.publish_host: _bond1:ipv4_ #发布给集群中其他节点知道的地址 discovery.zen.ping.unicast.hosts集群中其他节点ip:tcp端口,用来联系集群中其他节点1234discovery.zen.ping.unicast.hosts: - 192.168.1.10:9300 - 192.168.1.11 - seeds.mydomain.com discovery.zen.minimum_master_nodes最小主节点数目,为了防止脑裂,需要设置发现超过半数的主节点候选者才能组成集群1discovery.zen.minimum_master_nodes: 2","categories":[],"tags":[{"name":"es","slug":"es","permalink":"https://alreadygo.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://alreadygo.github.io/tags/elasticsearch/"}]},{"title":"es集群启动系统配置检查","slug":"es集群启动系统配置检查","date":"2017-11-11T12:32:21.000Z","updated":"2019-10-10T11:48:38.202Z","comments":true,"path":"2017/11/11/es集群启动系统配置检查/","link":"","permalink":"https://alreadygo.github.io/2017/11/11/es集群启动系统配置检查/","excerpt":"","text":"堆大小检查./bin/elasticsearch文件1ES_HEAP_SIZE=20G ./conf/jvm.options12-Xms2g -Xmx2g 把xms(堆初始化大小)和xmx(最大堆大小)设为相等 堆太小oom,堆太大gc停止时间越长 xmx不要超过机器物理内存的50% 因为jvm使用压缩对象指针,不要把xmx设超过临界点,临界点一般在靠近32G,正确的日志如下: 1heap size [1.9gb], compressed ordinary object pointers [true] 尽量保持在zero-based compressed oops临界点以下,大多数系统临界点在26G是安全的,有一些系统可以达到30G可以在启动es的时候加上XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode两个jvm参数来检验下是否在临界点之下,会出现如下日志: 1heap address: 0x000000011be00000, size: 27648 MB, zero based Compressed Oops 这段说明zero-based compressed oops生效了,而不是像这样:1heap address: 0x0000000118400000, size: 28672 MB, Compressed Oops with base: 0x00000001183ff000 open files 打开文件数 /max user processes 最大用户进程数/max locked memory jvm进程锁定到内存1234567891011121314151617[esadmin]$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 515100max locked memory (kbytes, -l) unlimitedmax memory size (kbytes, -m) unlimitedopen files (-n) 65535pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 65535virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited /etc/security/limits.conf中配置 检查mmap count至少26214412$ sysctl vm.max_map_countvm.max_map_count = 262144 在/etc/sysctl.conf中修改vm.max_map_count后,运行sysctl vm.max_map_count 检查插件没有head123456$ ./bin/plugin list - analysis-ik - delete-by-query - mapper-murmur3 - mapper-size - repository-hdfs","categories":[],"tags":[{"name":"es","slug":"es","permalink":"https://alreadygo.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://alreadygo.github.io/tags/elasticsearch/"}]},{"title":"es模块配置-集群","slug":"es模块配置-集群","date":"2017-11-08T12:30:22.000Z","updated":"2019-10-10T11:48:38.202Z","comments":true,"path":"2017/11/08/es模块配置-集群/","link":"","permalink":"https://alreadygo.github.io/2017/11/08/es模块配置-集群/","excerpt":"","text":"配置分为static和dynamic两种,static配置在elasticsearch.yml,环境变量,或者在启动节点的命令行中;dynamic可以通过cluster-update-settings api动态更新. 集群主节点主要功能之一是决定哪个分片分配到哪个节点,什么时候在节点间移动分片来平衡集群 分片分配配置cluster.routing.allocation.enable:all什么样的分片可以被分配 all primaries 仅分配主分片 new_primaries 仅分配新建索引的主分片 none 不允许分配分片cluster.routing.allocation.node_concurrent_recoveries:2一个节点上并发恢复分片的数目cluster.routing.allocation.node_initial_primaries_recoveries:4并发从本地磁盘恢复分片的数目cluster.routing.allocation.same_shard.host:false同一台机器有多个节点的时候,检查同一分片是否重复分配indices.recovery.concurrent_streams:3indices.recovery.concurrent_small_file_streams:2 分片平衡配置cluster.routing.rebalance.enable:all是否平衡分片 all primaries 仅平衡主分片 replicas 仅平衡副本分片 nonecluster.routing.allocation.allow_rebalance:indices_all_active什么时候允许平衡 always indices_primaries_active 当集群中所有的主分片都分配好了 indices_all_active 当集群中所有主分片和副本分片都分配好了cluster.routing.allocation.cluster_concurrent_rebalance:2集群允许并发平衡分片的数目 分片会被放在哪儿?不管平衡算法如何,forced awareness或者allocation filtering的优先级更高 cluster.routing.allocation.balance.shard:0.45f单个节点上分片分配的权重 cluster.routing.allocation.balance.index:0.55f单个节点每个索引分片数目的权重 cluster.routing.allocation.balance.threshold:1.0f平衡门槛,值越高越不积极去平衡分片 基于磁盘的分片分配cluster.routing.allocation.disk.threshold_enabled:true是否开启磁盘分配 cluster.routing.allocation.disk.watermark.low:85%磁盘检查低水位线,一旦磁盘使用率超过这个水位线,es将不会给该节点分配新的分片,可以设置百分比也可以设成绝对数值 cluster.routing.allocation.disk.watermark.high:90%磁盘检查高水位线,一旦结果超过这个水位线es会尝试把该节点上的分片重新分配到其他节点 cluster.info.update.interval:30s磁盘检查时间间隔 cluster.routing.allocation.disk.include_relocations:true当计算磁盘使用率的时候是否把正在重新分配的分片考虑进来 分片分配感应cluster.routing.allocation.awareness.force.zone.values: zone1,zone2正常的感应,如果一个zone联系不上其他zone,同一分片还是会分配到同一个zone上;配置了这个参数后,同一主分片和副本分片不允许分配到同一zone上 cluster.routing.allocation.awareness.attributes: rack_id,zone启动集群时,指定rack_id,当使用感应属性时,没有该属性的节点将不会被分配分片 ./bin/elasticsearch –node.rack_id rack_one 感应属性,可设多个值,逗号分隔,执行search或者get操作时,会优先搜索感应群组中的分片,这样通常会更快;当有多个机架时,es会移动分片来保证同一机架内不会存在同一索引的同一主副分片; 分片过滤cluster.routing.allocation.include.{attribute}分配索引到满足条件的节点(逗号分隔,至少满足一个) cluster.routing.allocation.require.{attribute}分配索引到满足条件的节点(逗号分隔,全部满足) cluster.routing.allocation.exclude.{attribute}分配索引到不满足条件的节点 attribute的取值,支持通配符 _name 节点名 _ip 节点ip _host 节点主机名其他集群配置cluster.blocks.read_only:false整个集群只可读,不能创建删除索引logger开头的配置用来管理日志,比如logger.indices.recovery","categories":[],"tags":[{"name":"es","slug":"es","permalink":"https://alreadygo.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://alreadygo.github.io/tags/elasticsearch/"}]},{"title":"es集群滚动重启","slug":"es集群滚动重启","date":"2017-10-22T00:21:48.000Z","updated":"2019-10-10T11:48:38.202Z","comments":true,"path":"2017/10/22/es集群滚动重启/","link":"","permalink":"https://alreadygo.github.io/2017/10/22/es集群滚动重启/","excerpt":"","text":"禁止分片分配12345curl -XPUT &apos;/_cluster/settings?pretty&apos; -d &apos;&#123; &quot;transient&quot;: &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot; &#125;&#125;&apos; 关闭单个节点关闭节点1$ kill &lt;pid&gt; 执行维护/升级等操作比如替换./plugins下某个文件夹,替换完成后执行./bin/plugin list 查看插件是否正常1scp esadmin@172.18.187.2:~/es-ik/elasticsearch-analysis-ik-1.9.3.zip ./ 重启节点1$ ./bin/elasticsearch -d 打开自动分配12345curl -XPUT &apos;/_cluster/settings?pretty&apos; -d &apos;&#123; &quot;transient&quot;: &#123; &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot; &#125;&#125;&apos; 检查集群是否恢复完成active_shards_percent_as_number进度是100,负载中的分片relocating_shards,正在被初始化分片initializing_shards及为被分配的分片unassigned_shards等均为0时表示恢复完成1curl -XGET &apos;/_cluster/health?pretty&apos; files_percent,bytes_percent,translog_percent进度为100%时恢复完成1curl -XGET &apos;/_cat/recovery?v&amp;human&amp;active_only=true&amp;detailed=true&apos; 重复步骤1-5注意:检查allocation设置1curl -XGET &apos;/_cluster/settings?pretty&amp;filter_path=**.enable&apos;","categories":[],"tags":[{"name":"es","slug":"es","permalink":"https://alreadygo.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://alreadygo.github.io/tags/elasticsearch/"}]},{"title":"hexo blog","slug":"blog","date":"2017-05-22T00:21:48.000Z","updated":"2019-10-11T02:16:39.536Z","comments":true,"path":"2017/05/22/blog/","link":"","permalink":"https://alreadygo.github.io/2017/05/22/blog/","excerpt":"","text":"安装 $ npm install hexo-cli -g 初始化 $ hexo init blog $ cd blog 下载依赖 $ npm i 修改配置文件_config.yml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo # 自定义网站标题,作者,语言(跟主题有关),我这边主题支持zh-Hans简体中文title: AlreadyGosubtitle:description:author: Hui Zhoulanguage: zh-Hanstimezone:## 自定义urlurl: http://alreadygo.github.ioroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directory source为源码目录,public为生成物目录source_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = &apos;&apos;)# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: &apos;&apos; per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## https://github.com/iissnan/hexo-theme-nexttheme: next# Deployment## Docs: https://hexo.io/docs/deployment.html### npm i hexo-deployer-git --save#### 修改自定义部署git仓库及分支deploy: type: git repo: https://github.com/AlreadyGo/alreadyGo.github.io.git branch: master 安装next主题 $ mkdir themes/next$ curl -s https://api.github.com/repos/iissnan/hexo-theme-next/releases/latest | grep tarball_url | cut -d ‘“‘ -f 4 | wget -i - -O- | tar -zx -C themes/next –strip-components=1 生成static文件 $ hexo generate 删除static文件 $ hexo clean 在本地运行 $ hexo server 部署到github $ hexo deploy 常见插件安装https://hexo.io/plugins/这边安装了几个: $ npm i hexo-deployer-git –save //git部署 $ npm i hexo-wordcount –save //post字数统计 $ npm i hexo-generator-searchd –save //本地搜索","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://alreadygo.github.io/tags/hexo/"},{"name":"blog","slug":"blog","permalink":"https://alreadygo.github.io/tags/blog/"}]},{"title":"shaowsocks","slug":"shaowsocks","date":"2017-03-21T02:53:15.000Z","updated":"2019-10-10T11:48:38.203Z","comments":true,"path":"2017/03/21/shaowsocks/","link":"","permalink":"https://alreadygo.github.io/2017/03/21/shaowsocks/","excerpt":"","text":"本脚本适用环境系统支持：CentOS，Debian，Ubuntu内存要求：≥128M关于本脚本一键安装 ShadowsocksR 服务端。请下载与之配套的客户端程序来连接。（以下客户端只有 Windows 客户端和 Python 版客户端可以使用 SSR 新特性，其他原版客户端只能以兼容的方式连接 SSR 服务器） 默认配置服务器端口：自己设定（如不设定，默认为 8989）客户端端口：1080密码：自己设定（如不设定，默认为teddysun.com）客户端下载 windows mac os linux android 使用方法使用root用户登录，运行以下命令 wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh chmod +x shadowsocksR.sh ./shadowsocksR.sh 2&amp;gt;&amp;amp;1 | tee shadowsocksR.log 安装完成后，脚本提示如下 Congratulations, ShadowsocksR install completed! Server IP:your_server_ip Server Port:your_server_port Password:your_password Local IP:127.0.0.1 Local Port:1080 Protocol:origin obfs:plain Encryption Method:aes-256-cfb Welcome to visit:https://shadowsocks.be/9.html If you want to change protocol &amp;amp; obfs, reference URL: https://github.com/breakwa11/shadowsocks-rss/wiki/Server-Setup Enjoy it! 卸载方法使用 root 用户登录，运行以下命令： ./shadowsocksR.sh uninstall 查看运行状态 /etc/init.d/shadowsocks status 可以查看 ShadowsocksR 进程是否已经启动。本脚本安装完成后，已将 ShadowsocksR 自动加入开机自启动。 使用命令 启动：/etc/init.d/shadowsocks start 停止：/etc/init.d/shadowsocks stop 重启：/etc/init.d/shadowsocks restart 状态：/etc/init.d/shadowsocks status 配置文件路径：/etc/shadowsocks.json日志文件路径：/var/log/shadowsocks.log代码安装目录：/usr/local/shadowsocks多用户配置 sample： { &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_ipv6&quot;: &quot;[::]&quot;, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:{ &quot;8989&quot;:&quot;password1&quot;, &quot;8990&quot;:&quot;password2&quot;， &quot;8991&quot;:&quot;password3&quot; }, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;protocol&quot;: &quot;origin&quot;, &quot;protocol_param&quot;: &quot;&quot;, &quot;obfs&quot;: &quot;plain&quot;, &quot;obfs_param&quot;: &quot;&quot;, &quot;redirect&quot;: &quot;&quot;, &quot;dns_ipv6&quot;: false, &quot;fast_open&quot;: false, &quot;workers&quot;: 1 } 如果你想修改配置文件，请参考：https://github.com/breakwa11/shadowsocks-rss/wiki/Server-Setup 参考链接 https://github.com/breakwa11/shadowsocks-rss","categories":[],"tags":[{"name":"shadowsocks","slug":"shadowsocks","permalink":"https://alreadygo.github.io/tags/shadowsocks/"},{"name":"breakwall","slug":"breakwall","permalink":"https://alreadygo.github.io/tags/breakwall/"}]},{"title":"设置npm代理","slug":"设置npm代理","date":"2017-01-21T17:07:17.000Z","updated":"2019-10-10T11:48:38.203Z","comments":true,"path":"2017/01/22/设置npm代理/","link":"","permalink":"https://alreadygo.github.io/2017/01/22/设置npm代理/","excerpt":"","text":"配置镜像by config command npm config set registry http://registry.cnpmjs.org npm info underscore （如果上面配置正确这个命令会有字符串response） 命令行指定 npm –registry http://registry.cnpmjs.org info underscore 编辑 ~/.npmrc 加入下面内容 registry = http://registry.cnpmjs.org 设置代理 npm config set proxy http://server:port npm config set https-proxy http://server:port 如果需要认证的话可以这样设置： npm config set proxy http://username:password@server:portnpm confit set https-proxy http://username:password@server:port 如果代理不支持https的话需要修改npm存放package的网站地址。 npm config set registry “http://registry.npmjs.org/&quot; 使用nrm快速切换npm源 nrm 是一个 NPM 源管理器，允许你快速地在如下 NPM 源间切换 列表项目 npm cnpm strongloop enropean australia nodejitsu taobao Install sudo npm install -g nrm 列出可用的源： ~ nrm ls npm —- https://registry.npmjs.org/ cnpm — http://r.cnpmjs.org/ taobao - http://registry.npm.taobao.org/ eu —– http://registry.npmjs.eu/ au —– http://registry.npmjs.org.au/ sl —– http://npm.strongloop.com/ nj —– https://registry.nodejitsu.com/ pt —– http://registry.npmjs.pt/ 切换： ~ nrm use taobao Registry has been set to: http://registry.npm.taobao.org/ 增加源： nrm add [home] 删除源： nrm del 测试速度： nrm test","categories":[],"tags":[{"name":"js","slug":"js","permalink":"https://alreadygo.github.io/tags/js/"},{"name":"npm","slug":"npm","permalink":"https://alreadygo.github.io/tags/npm/"}]},{"title":"linux下安装mysql常见问题","slug":"linux下安装mysql常见问题","date":"2017-01-20T17:07:17.000Z","updated":"2019-10-10T11:48:38.203Z","comments":true,"path":"2017/01/21/linux下安装mysql常见问题/","link":"","permalink":"https://alreadygo.github.io/2017/01/21/linux下安装mysql常见问题/","excerpt":"","text":"1.无法远程连接mysql 1130 GRANT ALL PRIVILEGES ON . TO ‘myuser‘@’%’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; 2.服务端中文乱码 [mysqld] character_set_server=utf8 service mysql restart 此时, mysql -u root -pstatus 会有类似的结果:Server characterset: utf8","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://alreadygo.github.io/tags/mysql/"},{"name":"linux","slug":"linux","permalink":"https://alreadygo.github.io/tags/linux/"}]}]}